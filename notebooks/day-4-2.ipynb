{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca6f6ed6-79e9-4efc-836a-040000ce8c89",
   "metadata": {
    "id": "ca6f6ed6-79e9-4efc-836a-040000ce8c89",
    "tags": []
   },
   "source": [
    "# day 4-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a0e4e4",
   "metadata": {
    "id": "05a0e4e4"
   },
   "source": [
    "このノートブックの実行例は[こちら(HTML版)](https://github.com/haradatm/lecture-gssm2025/blob/main/notebooks-samples/day-4-2.html.zip)で確認できます"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b35620",
   "metadata": {
    "id": "63b35620"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ac3570",
   "metadata": {
    "id": "b3ac3570"
   },
   "source": [
    "## 0. 準備"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcaee83",
   "metadata": {
    "id": "9bcaee83"
   },
   "source": [
    "### 0.1 必要なパッケージのインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d16f40",
   "metadata": {
    "id": "d9d16f40"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!sudo apt-get update\n",
    "!sudo apt-get install -y automake autoconf perl libtool graphviz libgraphviz-dev\n",
    "!pip install -U japanize_matplotlib pyvis pygraphviz mca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac82eeb",
   "metadata": {
    "id": "7ac82eeb"
   },
   "source": [
    "教材のダウンロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e1d717",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "32e1d717",
    "outputId": "d7f4b57a-2354-43af-d569-b05d77f69e41"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/haradatm/lecture-gssm2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92336b59",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "92336b59",
    "outputId": "859fb4e8-363d-444e-ea56-7760bc796bbd"
   },
   "outputs": [],
   "source": [
    "!ln -s lecture-gssm2025/notebooks/gssm_utils.py ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba650eb",
   "metadata": {
    "id": "2ba650eb"
   },
   "source": [
    "### 0.2 MeCab インストール (時間目安: 約3分)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c61f959",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5c61f959",
    "outputId": "875c3dbf-b992-4b34-9bf7-b412b194466d"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "!bash lecture-gssm2025/scripts/install_mecab.sh >> install_mecab.log 2>&1\n",
    "!tail -n 1 install_mecab.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ad83d7",
   "metadata": {
    "id": "10ad83d7"
   },
   "source": [
    "### 0.3 CaboCha インストール (時間目安: 約4分)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db89de7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5db89de7",
    "outputId": "15943891-0d90-45b3-fc23-df39bf5240af"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "!bash lecture-gssm2025/scripts/install_cabocha.sh >> install_cabocha.log 2>&1\n",
    "!tail -n 1 install_cabocha.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2808ecc0",
   "metadata": {
    "id": "2808ecc0"
   },
   "source": [
    "### 0.4 セッションの再起動"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc081282",
   "metadata": {
    "id": "cc081282"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6dfa20",
   "metadata": {},
   "source": [
    "セッションの再起動後は,以下のセルから実行してください. **注意: これより前のセルを再度実行する必要はありません!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feadaa4f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0482a0",
   "metadata": {},
   "source": [
    "### 0.5 辞書登録"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5539f9f6",
   "metadata": {},
   "source": [
    "追加したい形態素の情報を CSV ファイル(user_dic.csv)に追記する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594dc41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo '\"泉質\",-1,-1,1,名詞,一般,*,*,*,*,泉質,センシツ,センシツ,USER\"' >> ./tools/usr/local/lib/mecab/dic/ipadic/user_dic.csv\n",
    "!echo '\"海鮮丼\",-1,-1,1,名詞,一般,*,*,*,*,海鮮丼,カイセンドン,カイセンドン,USER\"' >> ./tools/usr/local/lib/mecab/dic/ipadic/user_dic.csv\n",
    "!echo '\"スカイツリー\",-1,-1,1,名詞,一般,*,*,*,*,スカイツリー,スカイツリー,スカイツリー,USER\"' >> ./tools/usr/local/lib/mecab/dic/ipadic/user_dic.csv\n",
    "!echo '\"バスタオル\",-1,-1,1,名詞,一般,*,*,*,*,バスタオル,バスタオル,バスタオル,USER\"' >> ./tools/usr/local/lib/mecab/dic/ipadic/user_dic.csv\n",
    "!cat ./tools/usr/local/lib/mecab/dic/ipadic/user_dic.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dac0cd",
   "metadata": {},
   "source": [
    "CSVファイル(user_dic.csv)をコンパイルして辞書(user.dic)を作成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2ed7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./tools/usr/local/libexec/mecab/mecab-dict-index \\\n",
    "-d ./tools/usr/local/lib/mecab/dic/ipadic \\\n",
    "-u ./tools/usr/local/lib/mecab/dic/ipadic/user.dic \\\n",
    "-f utf-8 -t utf-8 \\\n",
    "./tools/usr/local/lib/mecab/dic/ipadic/user_dic.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c991587",
   "metadata": {},
   "source": [
    "### 0.6 確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6c21f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import MeCab\n",
    "tagger = MeCab.Tagger(\"-r ./tools/usr/local/etc/mecabrc\")\n",
    "\n",
    "print(tagger.parse(\"この泉質は極上です\"))\n",
    "print(tagger.parse(\"この海鮮丼は美味しいです\"))\n",
    "print(tagger.parse(\"近くにスカイツリーがあります\"))\n",
    "print(tagger.parse(\"浴室にバスタオルがありません\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7e8885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import CaboCha\n",
    "\n",
    "cp = CaboCha.Parser(\"-r ./tools/usr/local/etc/cabocharc\")\n",
    "print(cp.parse(\"この泉質は極上です\").toString(CaboCha.FORMAT_LATTICE))\n",
    "print(cp.parse(\"この海鮮丼は美味しいです\").toString(CaboCha.FORMAT_LATTICE))\n",
    "print(cp.parse(\"近くにスカイツリーがあります\").toString(CaboCha.FORMAT_LATTICE))\n",
    "print(cp.parse(\"浴室にバスタオルがありません\").toString(CaboCha.FORMAT_LATTICE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef97ca4",
   "metadata": {
    "id": "4ef97ca4"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8038e0af-8843-493e-831f-2bceee5b6656",
   "metadata": {
    "id": "8038e0af-8843-493e-831f-2bceee5b6656"
   },
   "source": [
    "## 1. テキスト分析 (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110e3e63",
   "metadata": {
    "id": "110e3e63"
   },
   "source": [
    "### 1.0 事前準備 (定義済み関数の読み込み)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfad7a6b",
   "metadata": {
    "id": "bfad7a6b"
   },
   "source": [
    "#### 1.0.1 定義済み関数の読み込み"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cb3e5b",
   "metadata": {
    "id": "f4cb3e5b"
   },
   "source": [
    "以下のセルを**修正せず**に実行してください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87809c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# 再現性のために乱数を固定する\n",
    "seed = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# 定義済み関数をインポートする\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import gssm_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1867f595",
   "metadata": {
    "id": "1867f595"
   },
   "source": [
    "#### 1.0.1 データのダウンロード (前回ダウンロード済みのためスキップ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2368d5e8",
   "metadata": {
    "id": "2368d5e8"
   },
   "source": [
    "以下のデータがダウンロード済みです"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045f604b",
   "metadata": {
    "id": "045f604b"
   },
   "source": [
    "| ファイル名 | 件数 | データセット | 備考 |\n",
    "| --- | --- | --- | --- |\n",
    "| rakuten-1000-2024-2025.xlsx.zip | 10,000 | •レジャー+ビジネスの 10エリア<br>•エリアごと 1,000件 (ランダムサンプリング)<br>•期間: 2024/1~2025 GW明け | 本講義の全体を通して使用する |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c5cc0b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "97c5cc0b",
    "outputId": "f0f5efd2-46b8-4319-f454-f56e69f26e20"
   },
   "outputs": [],
   "source": [
    "# rakuten-1000-2024-2025.xlsx.zip をダウンロードする\n",
    "FILE_ID = \"1yKabZ7qJMRrIrP4Vtq-RrSZAqFsZriQS\"\n",
    "!gdown {FILE_ID}\n",
    "!unzip -o rakuten-1000-2024-2025.xlsx.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bba6d12",
   "metadata": {
    "id": "6bba6d12"
   },
   "source": [
    "#### 1.0.2 データの読み込み (DataFrame型)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21af64cf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "id": "21af64cf",
    "outputId": "6fba1cd3-f962-4c66-8964-f8747f80ac18"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "all_df = pd.read_excel(\"rakuten-1000-2024-2025.xlsx\")\n",
    "print(all_df.shape)\n",
    "display(all_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c983a2",
   "metadata": {
    "id": "46c983a2"
   },
   "source": [
    "#### 1.0.3 「文書-抽出語」表 を作成する (Top 1000語)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e99c1ac",
   "metadata": {
    "id": "6e99c1ac"
   },
   "source": [
    "コメント列から単語を抽出する (単語を品詞「名詞」「形容詞」「未知語」で絞り込む)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f750bf2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "id": "9f750bf2",
    "outputId": "ee85c0ad-41ad-4c31-d7a7-db294ac0bdce"
   },
   "outputs": [],
   "source": [
    "# 必要ライブラリのインポート\n",
    "from collections import defaultdict\n",
    "import MeCab\n",
    "\n",
    "# mecab の初期化\n",
    "tagger = MeCab.Tagger(\"-r ./tools/usr/local/etc/mecabrc --unk-feature 未知語\")\n",
    "\n",
    "# 単語頻度辞書の初期化\n",
    "word_counts = defaultdict(lambda: 0)\n",
    "\n",
    "# 抽出語情報リストの初期化\n",
    "words = []\n",
    "\n",
    "# 半角->全角変換マクロを定義する\n",
    "ZEN = \"\".join(chr(0xff01 + i) for i in range(94))\n",
    "HAN = \"\".join(chr(0x21 + i) for i in range(94))\n",
    "HAN2ZEN = str.maketrans(HAN, ZEN)\n",
    "\n",
    "# ストップワードを定義する\n",
    "stopwords =  [\"する\", \"それ\", \"なる\", \"ない\", \"そこ\", \"これ\" ,\"ある\"]\n",
    "stopwords += [\"湯畑\"]\n",
    "\n",
    "# データ1行ごとのループ\n",
    "for index, row in all_df.iterrows():\n",
    "\n",
    "    # 半角->全角変換した後で, mecab で解析する\n",
    "    node = tagger.parseToNode(row[\"コメント\"].translate(HAN2ZEN))\n",
    "\n",
    "    # 形態素ごとのループ\n",
    "    while node:\n",
    "        # 解析結果を要素ごとにバラす\n",
    "        features = node.feature.split(',')\n",
    "\n",
    "        # 品詞1 を取り出す\n",
    "        pos1 = features[0]\n",
    "\n",
    "        # 品詞2 を取り出す\n",
    "        pos2 = features[1] if len(features) > 1 else \"\"\n",
    "\n",
    "        # 原形 を取り出す\n",
    "        base = features[6] if len(features) > 6 else None\n",
    "\n",
    "        # 原型がストップワードに含まれない単語のみ抽出する\n",
    "        if base not in stopwords:\n",
    "\n",
    "            # 「名詞-一般」\n",
    "            if (pos1 == \"名詞\" and pos2 == \"一般\"):\n",
    "                base = base if base is not None else node.surface\n",
    "                postag = \"名詞\"\n",
    "                key = (base, postag)\n",
    "\n",
    "                # 単語頻度辞書をカウントアップする\n",
    "                word_counts[key] += 1\n",
    "\n",
    "                # 抽出語情報をリストに追加する\n",
    "                words.append([index + 1, base, postag, row[\"カテゴリー\"], row[\"エリア\"], key])\n",
    "\n",
    "            # 「形容動詞」\n",
    "            elif (pos1 == \"名詞\" and pos2 == \"形容動詞語幹\"):\n",
    "                base = base if base is not None else node.surface\n",
    "                base = f\"{base}\"\n",
    "                postag = \"形容動詞\"\n",
    "                key = (base, postag)\n",
    "\n",
    "                # 単語頻度辞書をカウントアップする\n",
    "                word_counts[key] += 1\n",
    "\n",
    "                # 抽出語情報をリストに追加する\n",
    "                words.append([index + 1, base, postag, row[\"カテゴリー\"], row[\"エリア\"], key])\n",
    "\n",
    "            # 「形容詞」\n",
    "            elif pos1 == \"形容詞\":\n",
    "                base = base if base is not None else node.surface\n",
    "                postag = \"形容詞\"\n",
    "                key = (base, postag)\n",
    "\n",
    "                # 単語頻度辞書をカウントアップする\n",
    "                word_counts[key] += 1\n",
    "\n",
    "                # 抽出語情報をリストに追加する\n",
    "                words.append([index + 1, base, postag, row[\"カテゴリー\"], row[\"エリア\"], key])\n",
    "\n",
    "            # 「未知語」\n",
    "            elif pos1 == \"未知語\":\n",
    "                base = base if base is not None else node.surface\n",
    "                postag = \"未知語\"\n",
    "                key = (base, postag)\n",
    "\n",
    "                # 単語頻度辞書をカウントアップする\n",
    "                word_counts[key] += 1\n",
    "\n",
    "                # 抽出語情報をリストに追加する\n",
    "                words.append([index + 1, base, postag, row[\"カテゴリー\"], row[\"エリア\"], key])\n",
    "\n",
    "        # 次の形態素へ\n",
    "        node = node.next\n",
    "\n",
    "# DataFrme 型に整える\n",
    "columns = [\n",
    "    \"文書ID\",\n",
    "    # \"単語ID\",\n",
    "    \"表層\",\n",
    "    \"品詞\",\n",
    "    \"カテゴリー\",\n",
    "    \"エリア\",\n",
    "    \"dict_key\",\n",
    "]\n",
    "docs_df = pd.DataFrame(words, columns=columns)\n",
    "\n",
    "# DataFrame を表示する\n",
    "print(docs_df.shape)\n",
    "display(docs_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acea1bc",
   "metadata": {
    "id": "9acea1bc"
   },
   "source": [
    "抽出語の出現頻度をカウントする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e05e96",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "d1e05e96",
    "outputId": "69de2593-339b-4590-8e6b-1767a460e9ab"
   },
   "outputs": [],
   "source": [
    "# 「文書-抽出語」 表から単語の出現回数をカウントする\n",
    "word_list = []\n",
    "for i, (k, v) in enumerate(sorted(word_counts.items(), key=lambda x:x[1], reverse=True)):\n",
    "    word_list.append((i, k[0], v, k))\n",
    "\n",
    "# DataFrame 型に整える\n",
    "columns = [\n",
    "    \"単語ID\",\n",
    "    \"表層\",\n",
    "    \"出現頻度\",\n",
    "    \"dict_key\"\n",
    "]\n",
    "\n",
    "# DataFrame を表示する\n",
    "word_counts_df = pd.DataFrame(word_list, columns=columns)\n",
    "print(word_counts_df.shape)\n",
    "display(word_counts_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d2d301",
   "metadata": {
    "id": "d5d2d301"
   },
   "source": [
    "「文書-抽出語」表を作成する (出現回数 Top 1000語)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724abed1",
   "metadata": {
    "id": "724abed1"
   },
   "outputs": [],
   "source": [
    "# 「単語出現回数」 表から出現回数Top 1000語のみ抽出する\n",
    "word_counts_1000_df = word_counts_df[0:1000]\n",
    "\n",
    "# 「文書-抽出語」 表も出現回数Top 150語のみに絞り込む\n",
    "merged_df = pd.merge(docs_df, word_counts_1000_df, how=\"inner\", on=\"dict_key\", suffixes=[\"\", \"_right\"])\n",
    "docs_1000_df = merged_df[[\"文書ID\", \"単語ID\", \"表層\", \"品詞\", \"カテゴリー\", \"エリア\", \"dict_key\"]]\n",
    "\n",
    "# 「カテゴリー,エリア」でクロス集計する\n",
    "cross_1000_df = pd.crosstab(\n",
    "    [\n",
    "        docs_1000_df['カテゴリー'],\n",
    "        docs_1000_df['エリア'],\n",
    "        docs_1000_df['文書ID']\n",
    "    ],\n",
    "    docs_1000_df['単語ID'], margins=False\n",
    ")\n",
    "cross_1000_df.columns = word_counts_1000_df[\"表層\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea78890",
   "metadata": {},
   "source": [
    "### 1.1 カテゴリーやエリアごとのユーザーの注目ポイントを押さえる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f116b5",
   "metadata": {},
   "source": [
    "「文書-抽出語」表を {0,1} に変換する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2a9f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 「文書-抽出語」 表を {0,1} に変換する\n",
    "cross_1000_df[cross_1000_df > 0] = 1\n",
    "\n",
    "# DataFrame を表示する\n",
    "print(cross_1000_df.shape)\n",
    "display(cross_1000_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c654cf0",
   "metadata": {},
   "source": [
    "#### 2.1.2 共起行列を作成する (外部変数-抽出語)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cacb5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 「カテゴリー」のクロス集計と「エリア」のクロス集計を連結する\n",
    "aggregate_df = pd.concat(\n",
    "    [\n",
    "        cross_1000_df.groupby(level='カテゴリー').sum(),\n",
    "        cross_1000_df.groupby(level='エリア').sum()\n",
    "    ]\n",
    ")\n",
    "\n",
    "# DataFrame を表示する\n",
    "print(aggregate_df.shape)\n",
    "display(aggregate_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3b08bd",
   "metadata": {},
   "source": [
    "#### 2.1.3 Jaccard 係数を求める (外部変数-抽出語)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc5c0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 抽出語の出現回数を取得する\n",
    "word_counts = cross_1000_df.sum(axis=0).values\n",
    "\n",
    "# 属性(外部変数)出現数を取得する\n",
    "attr_counts = np.hstack(\n",
    "    [\n",
    "        all_df.value_counts('カテゴリー').values,\n",
    "        all_df.value_counts('エリア').values\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 共起行列の中身を Jaccard 係数に入れ替える\n",
    "jaccard_attrs_df = gssm_utils.jaccard_attrs_coef(aggregate_df, attr_counts, word_counts, total=10000, conditional=False)\n",
    "\n",
    "# DataFrame を表示する\n",
    "print(jaccard_attrs_df.shape)\n",
    "display(jaccard_attrs_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7911c0b",
   "metadata": {},
   "source": [
    "#### 2.1.4 特徴語ランキング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d073c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 「カテゴリ」や「エリア」ごとに Jaccard 係数のTop 10語を抽出する\n",
    "df_list = []\n",
    "for index, row in jaccard_attrs_df.iterrows():\n",
    "    df_list.append(row.iloc[np.argsort(row.values)[::-1][:10]].reset_index())\n",
    "\n",
    "# 「カテゴリ」や「エリア」ごとの Jaccard 係数のTop 10 を横方向に連結した DetaFrame を作成する\n",
    "ranking_df = pd.DataFrame(pd.concat(df_list, axis=1))\n",
    "ranking_df.columns = np.array([c for pair in [[x,f\"jaccard\"] for x in jaccard_attrs_df.index] for c in pair], dtype='object')\n",
    "\n",
    "# DataFrame を表示する\n",
    "display(ranking_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5872180",
   "metadata": {},
   "source": [
    "ファイルに出力する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d8813b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_df.to_csv(\"practice-4.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d78f7b",
   "metadata": {},
   "source": [
    "#### 2.1.5 ワードクラウド"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d4f0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# サブルーチン\n",
    "def sort_and_plot(name, group):\n",
    "\n",
    "    # 「カテゴリー」ごとに Jaccard 係数でソートする\n",
    "    sorted_columns = np.argsort(jaccard_attrs_df.loc[name].values)[::-1][:75]\n",
    "\n",
    "    # Jaccard 係数Top 75語をソートして抽出する\n",
    "    group_cross_df = group.iloc[:,sorted_columns]\n",
    "\n",
    "    # プロットする\n",
    "    ax = fig.add_subplot(4, 3, i+1)\n",
    "    gssm_utils.plot_wordcloud_ax(ax, \" \".join(group_cross_df.columns))\n",
    "    ax.set_title(name)\n",
    "\n",
    "\n",
    "# プロットの準備\n",
    "fig = plt.figure(figsize=(12, 9))\n",
    "\n",
    "i = 0\n",
    "# カテゴリごとのループ\n",
    "for name, group in cross_1000_df.groupby(level='カテゴリー'):\n",
    "    # サブルーチンを呼ぶ\n",
    "    sort_and_plot(name, group)\n",
    "    i += 1\n",
    "\n",
    "    # エリアごとのループ\n",
    "    for sub_name, sub_group in group.groupby(level='エリア'):\n",
    "        # サブルーチンを呼ぶ\n",
    "        sort_and_plot(sub_name, sub_group)\n",
    "        i += 1\n",
    "\n",
    "# プロットの仕上げ\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abcd155",
   "metadata": {},
   "source": [
    "#### 2.1.6 共起ネットワーク図 (カテゴリ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7856a084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 抽出語の出現回数を取得する\n",
    "word_counts = cross_1000_df.sum(axis=0).values\n",
    "\n",
    "# 属性(外部変数)出現数を取得する\n",
    "attr_counts = np.hstack(\n",
    "    [\n",
    "        all_df.value_counts('カテゴリー').values,\n",
    "    ]\n",
    ")\n",
    "\n",
    "# カテゴリのみの共起行列(共起度数)を取得する\n",
    "df = aggregate_df.loc[[\"A_レジャー\",\"B_ビジネス\"],:]\n",
    "\n",
    "# 共起行列(共起度数)で共起ネットワーク図を作成する\n",
    "gssm_utils.plot_attrs_network(df, attr_counts, word_counts, np.sort(df.values.reshape(-1))[::-1][60], width=8, height=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4340d50",
   "metadata": {},
   "source": [
    "#### 2.1.7 共起ネットワーク図 (エリア)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b04192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 抽出語の出現回数を取得する\n",
    "word_counts = cross_1000_df.sum(axis=0).values\n",
    "\n",
    "# 属性(外部変数)出現数を取得する\n",
    "attr_counts = np.hstack(\n",
    "    [\n",
    "        all_df.value_counts('エリア').values,\n",
    "    ]\n",
    ")\n",
    "\n",
    "# カテゴリのみの共起行列(共起度数)を取得する\n",
    "df = aggregate_df.iloc[2:,:]\n",
    "\n",
    "# 共起行列((共起度数)で共起ネットワーク図を作成する\n",
    "gssm_utils.plot_attrs_network(df, attr_counts, word_counts, np.sort(df.values.reshape(-1))[::-1][120], width=8, height=8, pyvis=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fc98fc",
   "metadata": {},
   "source": [
    "#### 2.1.8 トピックを抽出する (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c429fd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要ライブラリのインポート\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "\n",
    "# ライブラリ LDA によるトピック抽出\n",
    "lda = LDA(max_iter=25, learning_method='batch', random_state=42, n_jobs=-1, n_components=6)\n",
    "lda.fit(cross_1000_df.values)\n",
    "\n",
    "# トピックごとに出現確率Top 20語を表示する\n",
    "n_top_words = 20\n",
    "feature_names = cross_1000_df.columns\n",
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    print(f\"Topic # {topic_idx+1}:\", end=\" \")\n",
    "    for i in topic.argsort()[:-n_top_words-1:-1]:\n",
    "        print(feature_names[i], end=\" \")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae27d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要ライブラリのインポート\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "\n",
    "# ライブラリ LDA によるトピック抽出\n",
    "lda = LDA(max_iter=25, learning_method='batch', random_state=42, n_jobs=-1, n_components=6)\n",
    "lda.fit(cross_1000_df.values)\n",
    "\n",
    "# トピックごとに出現確率Top 20語を表示する\n",
    "n_top_words = 20\n",
    "feature_names = cross_1000_df.columns\n",
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    print(f\"Topic # {topic_idx+1}:\", end=\" \")\n",
    "    for i in topic.argsort()[:-n_top_words-1:-1]:\n",
    "        print(feature_names[i], end=\" \")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993ddbdb",
   "metadata": {},
   "source": [
    "ChatGPT を使ってトピックを説明する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685ba39d",
   "metadata": {},
   "source": [
    "プロンプトの例:\n",
    "> 以下はトピックとトピックごとの高確率ワードです. これを読んで各トピックを簡潔に要約してください.\n",
    ">\n",
    "> Topic # 1\t温泉 風呂 良い 美味しい 露天風呂 宿 部屋 最高 …"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b373d9",
   "metadata": {},
   "source": [
    "結果の例:\n",
    "- Topic #1: 温泉・食事の満足度\n",
    "- Topic #2: スタッフと家族向けのサービス\n",
    "- Topic #3: 立地と利便性の高さ\n",
    "- Topic #4: サービスや施設の不満点\n",
    "- Topic #5: 部屋と設備の快適さ／不満\n",
    "- Topic #6: フロント対応と設備の不足"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2e4f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# トピックごとに出現確率Top 75語をプロットする\n",
    "n_top_words = 75\n",
    "gssm_utils.plot_topic_model(lda, feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66622a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# サブルーチン\n",
    "def sort_and_plot(name, group):\n",
    "\n",
    "    # 文書ごとのトピック比率を取得\n",
    "    doc_topic_distributions = lda.transform(group.values)\n",
    "\n",
    "    # 文書全体のトピック比率を計算（平均を取る）\n",
    "    overall_topic_distribution = np.mean(doc_topic_distributions, axis=0)\n",
    "\n",
    "    # プロットする\n",
    "    ax = fig.add_subplot(4, 3, i+1)\n",
    "    gssm_utils.plot_topic_distribution_ax(ax, overall_topic_distribution)\n",
    "    ax.set_title(name)\n",
    "\n",
    "# プロットの準備\n",
    "fig = plt.figure(figsize=(12, 9))\n",
    "\n",
    "i = 0\n",
    "# カテゴリごとのループ\n",
    "for name, group in cross_1000_df.groupby(level='カテゴリー'):\n",
    "    # サブルーチンを呼ぶ\n",
    "    sort_and_plot(name, group)\n",
    "    i += 1\n",
    "\n",
    "    # エリアごとのループ\n",
    "    for sub_name, sub_group in group.groupby(level='エリア'):\n",
    "        # サブルーチンを呼ぶ\n",
    "        sort_and_plot(sub_name, sub_group)\n",
    "        i += 1\n",
    "\n",
    "# プロットの仕上げ\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec185de7",
   "metadata": {
    "id": "ec185de7"
   },
   "source": [
    "### 1.2 カテゴリーやエリアごとのユーザーの注目ポイントの評価の違いを見つける"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aabc820",
   "metadata": {
    "id": "9aabc820"
   },
   "source": [
    "「文書-抽出語」表を {0,1} に変換する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cd3310",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473
    },
    "id": "24cd3310",
    "outputId": "5023e5f9-058a-4e38-cb7a-c6b3d0ceaeb1"
   },
   "outputs": [],
   "source": [
    "# 「文書-抽出語」 表を {0,1} に変換する\n",
    "cross_1000_df[cross_1000_df > 0] = 1\n",
    "\n",
    "# DataFrame を表示する\n",
    "print(cross_1000_df.shape)\n",
    "display(cross_1000_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6524d454",
   "metadata": {
    "id": "6524d454"
   },
   "source": [
    "#### 1.2.2 共起行列を作成する (外部変数-抽出語)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f241fe6d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473
    },
    "id": "f241fe6d",
    "outputId": "32ba219f-188a-4fdf-8a08-1c571b18defd"
   },
   "outputs": [],
   "source": [
    "# 「カテゴリー」のクロス集計と「エリア」のクロス集計を連結する\n",
    "aggregate_df = pd.concat(\n",
    "    [\n",
    "        cross_1000_df.groupby(level='カテゴリー').sum(),\n",
    "        cross_1000_df.groupby(level='エリア').sum()\n",
    "    ]\n",
    ")\n",
    "\n",
    "# DataFrame を表示する\n",
    "print(aggregate_df.shape)\n",
    "display(aggregate_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e384ac91",
   "metadata": {
    "id": "e384ac91"
   },
   "source": [
    "#### 1.2.3 Jaccard 係数を求める (外部変数-抽出語)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b008e42d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "b008e42d",
    "outputId": "8aba9a71-065b-46ab-95d9-638d04b47a2a"
   },
   "outputs": [],
   "source": [
    "# 抽出語の出現回数を取得する\n",
    "word_counts = cross_1000_df.sum(axis=0).values\n",
    "\n",
    "# 属性(外部変数)出現数を取得する\n",
    "attr_counts = np.hstack(\n",
    "    [\n",
    "        all_df.value_counts('カテゴリー').values,\n",
    "        all_df.value_counts('エリア').values\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 共起行列の中身を Jaccard 係数に入れ替える\n",
    "jaccard_attrs_df = gssm_utils.jaccard_attrs_coef(aggregate_df, attr_counts, word_counts, total=10000, conditional=False)\n",
    "\n",
    "# DataFrame を表示する\n",
    "print(jaccard_attrs_df.shape)\n",
    "display(jaccard_attrs_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccc5e1b",
   "metadata": {
    "id": "7ccc5e1b"
   },
   "source": [
    "#### 1.2.4 共起ネットワーク図"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b608a07",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4b608a07",
    "outputId": "08b0515d-3ae0-4ee9-d0b2-2d42eb7329b7"
   },
   "outputs": [],
   "source": [
    "# 必要ライブラリのインポート\n",
    "from scipy.sparse import csc_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# サブルーチン\n",
    "def sort_and_plot(name, group):\n",
    "\n",
    "    # 「カテゴリー」ごとに Jaccard 係数でソートする\n",
    "    sorted_columns = np.argsort(jaccard_attrs_df.loc[name].values)[::-1][:75]\n",
    "\n",
    "    # Jaccard 係数Top 75語をソートして抽出する\n",
    "    group_cross_df = group.iloc[:,sorted_columns]\n",
    "\n",
    "    # 共起行列を作成する\n",
    "    X = group_cross_df.values\n",
    "    X = csc_matrix(X)\n",
    "    Xc = (X.T * X)\n",
    "    Xc = np.triu(Xc.toarray())\n",
    "\n",
    "    # 共起行列を DataFrame に整える\n",
    "    group_cooccur_df = pd.DataFrame(Xc, columns=group_cross_df.columns, index=group_cross_df.columns)\n",
    "\n",
    "    # 共起行列の中身を Jaccard 係数に入れ替える\n",
    "    group_jaccard_df = gssm_utils.jaccard_coef(group_cooccur_df, group_cross_df)\n",
    "\n",
    "    # 抽出語の出現回数を取得する\n",
    "    word_counts = group_cross_df.sum(axis=0).values\n",
    "\n",
    "    # プロットする\n",
    "    ax = fig.add_subplot(4, 3, i+1)\n",
    "    pyvis_plot = gssm_utils.plot_cooccur_network_ax(ax, group_jaccard_df, word_counts, np.sort(group_jaccard_df.values.reshape(-1))[::-1][120], pyvis=True, name=f\"{name}.html\")\n",
    "    ax.set_title(name)\n",
    "    display(pyvis_plot)\n",
    "\n",
    "# プロットの準備\n",
    "# fig = plt.figure(figsize=(20, 28))\n",
    "fig = plt.figure(figsize=(28, 28))\n",
    "\n",
    "i = 0\n",
    "# カテゴリごとのループ\n",
    "for name, group in cross_1000_df.groupby(level='カテゴリー'):\n",
    "    # サブルーチンを呼ぶ\n",
    "    sort_and_plot(name, group)\n",
    "    i += 1\n",
    "\n",
    "    # エリアごとのループ\n",
    "    for sub_name, sub_group in group.groupby(level='エリア'):\n",
    "        # サブルーチンを呼ぶ\n",
    "        sort_and_plot(sub_name, sub_group)\n",
    "        i += 1\n",
    "\n",
    "# プロットの仕上げ\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29d66bd",
   "metadata": {
    "id": "c29d66bd"
   },
   "source": [
    "#### 1.2.5 係り受け行列を作成する (抽出語-抽出語)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb76aa7e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "bb76aa7e",
    "outputId": "72074464-259d-4215-f172-c9db1c355b21"
   },
   "outputs": [],
   "source": [
    "# 必要ライブラリのインポート\n",
    "from scipy.sparse import csc_matrix\n",
    "\n",
    "# 共起行列を作成する\n",
    "X = cross_1000_df.values\n",
    "X = csc_matrix(X)\n",
    "Xc = (X.T * X)\n",
    "# 対角成分のみにする\n",
    "Xc = np.triu(Xc.toarray())\n",
    "\n",
    "# DataFrame 型に整える\n",
    "cooccur_1000_df = pd.DataFrame(Xc, columns=cross_1000_df.columns, index=cross_1000_df.columns)\n",
    "\n",
    "# チャンク(文節)から単語を取り出す\n",
    "def get_words(tree, from_chunk, stopwords):\n",
    "\n",
    "    # チャンク(文節)の開始位置を取得する\n",
    "    beg = from_chunk.token_pos\n",
    "\n",
    "    # チャンクの開始位置を取得する\n",
    "    end = from_chunk.token_pos + from_chunk.token_size\n",
    "\n",
    "    # 抽出語情報リストの初期化\n",
    "    words = []\n",
    "\n",
    "    # チャンク(文節)ごとのループ\n",
    "    for i in range(beg, end):\n",
    "\n",
    "        # チャンク中の形態素を取り出す\n",
    "        token = tree.token(i)\n",
    "\n",
    "        # 解析結果を要素ごとにバラす\n",
    "        features = token.feature.split(',')\n",
    "\n",
    "        # 品詞1 を取り出す\n",
    "        pos1 = features[0]\n",
    "\n",
    "        # 品詞2 を取り出す\n",
    "        pos2 = features[1] if len(features) > 1 else \"\"\n",
    "\n",
    "        # 原形 を取り出す\n",
    "        base = features[6] if len(features) > 6 else None\n",
    "\n",
    "        # 原型がストップワードに含まれない単語のみ抽出する\n",
    "        if base not in stopwords:\n",
    "\n",
    "            # 「名詞-一般」\n",
    "            if (pos1 == \"名詞\" and pos2 == \"一般\"):\n",
    "                base = base if base is not None else node.surface\n",
    "                postag = \"名詞\"\n",
    "                key = (base, postag)\n",
    "\n",
    "                # 抽出語情報をリストに追加する\n",
    "                words.append(key)\n",
    "\n",
    "            # 「形容動詞」\n",
    "            elif (pos1 == \"名詞\" and pos2 == \"形容動詞語幹\"):\n",
    "                base = base if base is not None else node.surface\n",
    "                base = f\"{base}だ\"\n",
    "                postag = \"形容動詞\"\n",
    "                key = (base, postag)\n",
    "\n",
    "                # 抽出語情報をリストに追加する\n",
    "                words.append(key)\n",
    "\n",
    "            # 「形容詞」\n",
    "            elif pos1 == \"形容詞\":\n",
    "                base = base if base is not None else node.surface\n",
    "                postag = \"形容詞\"\n",
    "                key = (base, postag)\n",
    "\n",
    "                # 抽出語情報をリストに追加する\n",
    "                words.append(key)\n",
    "\n",
    "            # 「未知語」\n",
    "            elif pos1 == \"未知語\":\n",
    "                base = base if base is not None else node.surface\n",
    "                postag = \"未知語\"\n",
    "                key = (base, postag)\n",
    "\n",
    "                # 抽出語情報をリストに追加する\n",
    "                words.append(key)\n",
    "\n",
    "    # 抽出語情報をリストを返却する\n",
    "    return words\n",
    "\n",
    "\n",
    "# 必要ライブラリのインポート\n",
    "import CaboCha\n",
    "\n",
    "# cabocha の初期化\n",
    "cp = CaboCha.Parser(\"-r ./tools/usr/local/etc/cabocharc\")\n",
    "\n",
    "# 半角->全角変換マクロを定義する\n",
    "ZEN = \"\".join(chr(0xff01 + i) for i in range(94))\n",
    "HAN = \"\".join(chr(0x21 + i) for i in range(94))\n",
    "HAN2ZEN = str.maketrans(HAN, ZEN)\n",
    "\n",
    "# ストップワードを定義する\n",
    "stopwords =  [\"する\", \"それ\", \"なる\", \"ない\", \"そこ\", \"これ\" ,\"ある\"]\n",
    "stopwords += [\"湯畑\"]\n",
    "stopwords += ['*']  # 原形に 「'*'」 が出力された場合に除去するため\n",
    "\n",
    "# 係り受けペア辞書の初期化\n",
    "pair_counts = defaultdict(lambda: 0)\n",
    "pairs = []\n",
    "\n",
    "# データ1行ごとのループ\n",
    "for index, row in all_df.iterrows():\n",
    "\n",
    "    # 半角->全角変換した後で, cabocha で解析する\n",
    "    tree = cp.parse(row[\"コメント\"].translate(HAN2ZEN))\n",
    "\n",
    "    # 解析結果から空でないチャンク(文節)のリストを集める\n",
    "    chunks = {}\n",
    "    key = 0\n",
    "    for i in range(tree.size()):\n",
    "        tok = tree.token(i)\n",
    "        if tok.chunk:\n",
    "            chunks[key] = tok.chunk\n",
    "            key += 1\n",
    "\n",
    "    # 係り元と係り先の単語情報(原形と品詞)を集める\n",
    "    from_words, to_words = [], []\n",
    "    for from_chunk in chunks.values():\n",
    "        # 係り先がなければスキップ\n",
    "        if from_chunk.link < 0:\n",
    "            continue\n",
    "\n",
    "        # 係り先のチャンク(文節)を取得する\n",
    "        to_chunk = chunks[from_chunk.link]\n",
    "\n",
    "        # 係り元の単語情報(原形と品詞)を取得する\n",
    "        from_words = get_words(tree, from_chunk, stopwords)\n",
    "\n",
    "        # 係り先の単語情報(原形と品詞)を取得する\n",
    "        to_words = get_words(tree, to_chunk, stopwords)\n",
    "\n",
    "    # 係り受けペアと頻度を収集する\n",
    "    for f in from_words:\n",
    "        for t in to_words:\n",
    "            key = (f[0], t[0])\n",
    "            pair_counts[key] += 1\n",
    "\n",
    "\n",
    "# 係り受け行列を初期化する (共起行列と同じ形)\n",
    "Xd = np.zeros(cooccur_1000_df.shape)\n",
    "\n",
    "# 係り受けペアを係り受け列に変換する\n",
    "for (f,t), v in pair_counts.items():\n",
    "    columns = list(cooccur_1000_df.columns)\n",
    "    if f in columns and t in columns:\n",
    "        i = columns.index(f)\n",
    "        j = columns.index(t)\n",
    "        Xd[i,j] = v\n",
    "\n",
    "# DataFrme 型に整える\n",
    "dep_1000_df = pd.DataFrame(Xd, columns=cooccur_1000_df.columns, index=cooccur_1000_df.columns)\n",
    "print(dep_1000_df.shape)\n",
    "display(dep_1000_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f8201a",
   "metadata": {
    "id": "27f8201a"
   },
   "source": [
    "#### 1.2.6 係り受けネットワーク図"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42079cab",
   "metadata": {
    "id": "42079cab"
   },
   "outputs": [],
   "source": [
    "# 必要ライブラリのインポート\n",
    "from scipy.sparse import csc_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# サブルーチン\n",
    "def sort_and_plot(name, group, pos):\n",
    "\n",
    "    # 「カテゴリー」ごとに Jaccard 係数でソートする\n",
    "    sorted_columns = np.argsort(jaccard_attrs_df.loc[name].values)[::-1][:75]\n",
    "\n",
    "    # Jaccard 係数Top 75語をソートして抽出する\n",
    "    group_cross_df = group.iloc[:,sorted_columns]\n",
    "\n",
    "    # 抽出語の出現回数を取得する\n",
    "    word_counts = group_cross_df.sum(axis=0).values\n",
    "\n",
    "    # 共起行列を作成する\n",
    "    X = group_cross_df.values\n",
    "    X = csc_matrix(X)\n",
    "    Xc = (X.T * X)\n",
    "    Xc = np.triu(Xc.toarray())\n",
    "\n",
    "    # 共起行列を DataFrame に整える\n",
    "    group_cooccur_df = pd.DataFrame(Xc, columns=group_cross_df.columns, index=group_cross_df.columns)\n",
    "\n",
    "    # 係り受け行列(条件付き確率)を初期化する (共起行列と同じ形)\n",
    "    Xd = np.zeros(group_cooccur_df.shape)\n",
    "\n",
    "    # 係り受けペアを係り受け行列(条件付き確率)に変換する\n",
    "    for (f,t), v in pair_counts.items():\n",
    "\n",
    "        # 係り元と係り先の両方が列に含まれる\n",
    "        columns = list(group_cooccur_df.columns)\n",
    "        if f in columns and t in columns:\n",
    "            i = columns.index(f)\n",
    "            j = columns.index(t)\n",
    "\n",
    "            # 条件付き確率(係り受け頻度/係り先出現回数)を求める\n",
    "            Xd[i,j] = v / word_counts[i]\n",
    "\n",
    "    # 係り受け行列(条件付き確率)を DataFrame 型に整える\n",
    "    group_dependency_df = pd.DataFrame(Xd, columns=group_cross_df.columns, index=group_cross_df.columns)\n",
    "\n",
    "    # プロットする\n",
    "    ax = fig.add_subplot(4, 3, pos+1)\n",
    "    pyvis_plot = gssm_utils.plot_dependency_network_ax(ax, group_dependency_df, word_counts, np.sort(group_dependency_df.values.reshape(-1))[::-1][120], pyvis=False, name=f\"{name}.html\")\n",
    "    ax.set_title(name)\n",
    "    # display(pyvis_plot)\n",
    "\n",
    "    # 係り受けペアを条件付き確率で降順にソートし10件表示する\n",
    "    Xc = group_dependency_df.values\n",
    "    words = group_dependency_df.columns\n",
    "    flat_indices = np.argsort(Xc.ravel())[::-1][:10]\n",
    "    row_indices, col_indices = np.unravel_index(flat_indices, Xc.shape)\n",
    "    for idx in range(len(flat_indices)):\n",
    "        value = Xc[row_indices[idx], col_indices[idx]]\n",
    "        print(f\"[{name}] {words[row_indices[idx]]} - {words[col_indices[idx]]}: {value:.04f}\")\n",
    "\n",
    "# プロットの準備\n",
    "# fig = plt.figure(figsize=(20, 28))\n",
    "fig = plt.figure(figsize=(28, 28))\n",
    "\n",
    "i = 0\n",
    "# カテゴリごとのループ\n",
    "for name, group in cross_1000_df.groupby(level='カテゴリー'):\n",
    "    # サブルーチンを呼ぶ\n",
    "    sort_and_plot(name, group, i)\n",
    "    i += 1\n",
    "\n",
    "    # エリアごとのループ\n",
    "    for sub_name, sub_group in group.groupby(level='エリア'):\n",
    "        # サブルーチンを呼ぶ\n",
    "        sort_and_plot(sub_name, sub_group, i)\n",
    "        i += 1\n",
    "\n",
    "# プロットの仕上げ\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a95b8f1",
   "metadata": {
    "id": "4a95b8f1"
   },
   "source": [
    "### 1.3 高評価のエリアに倣って、低評価のエリアを改善するプランを提案する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d2c7ba",
   "metadata": {
    "id": "60d2c7ba"
   },
   "source": [
    "#### 1.3.1 対照的な2エリアを選択する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aa54e6",
   "metadata": {
    "id": "d7aa54e6"
   },
   "outputs": [],
   "source": [
    "# コーディングルール\n",
    "coding_pos = [\"良い\",\"美味しい\",\"広い\",\"多い\",\"素晴らしい\",\"嬉しい\",\"気持ちよい\",\"楽しい\",\"近い\",\"大きい\",\"気持ち良い\",\"温かい\",\"早い\",\"優しい\",\"新しい\",\"暖かい\",\"快い\",\"明るい\",\"美しい\",\"可愛い\",\"満足\"]\n",
    "coding_neg = [\"古い\",\"無い\",\"高い\",\"悪い\",\"小さい\",\"狭い\",\"少ない\",\"寒い\",\"遅い\",\"熱い\",\"欲しい\",\"暑い\",\"冷たい\",\"遠い\",\"臭い\",\"暗い\",\"うるさい\",\"ない\",\"無い\",\"残念\",\"改善\",\"不満\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decabd60",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473
    },
    "id": "decabd60",
    "outputId": "e7c5998f-087c-4102-d9b4-66f296084e01"
   },
   "outputs": [],
   "source": [
    "# DataFrame を初期化する\n",
    "cross_1000_ps_df = cross_1000_df.copy()\n",
    "cross_1000_ps_df['ポジ'] = 0\n",
    "cross_1000_ps_df['ネガ'] = 0\n",
    "cross_1000_ps_df['総合1-2'] = 0\n",
    "cross_1000_ps_df['総合4-5'] = 0\n",
    "\n",
    "# コーディングルールを適用する (ポジ・ネガ)\n",
    "pos_index = docs_df['表層'].str.contains(\"|\".join(coding_pos))\n",
    "neg_index = docs_df['表層'].str.contains(\"|\".join(coding_neg))\n",
    "cross_1000_ps_df.loc[cross_1000_ps_df.index.get_level_values('文書ID').isin(docs_df.loc[pos_index, '文書ID']), 'ポジ'] = 1\n",
    "cross_1000_ps_df.loc[cross_1000_ps_df.index.get_level_values('文書ID').isin(docs_df.loc[neg_index, '文書ID']), 'ネガ'] = 1\n",
    "\n",
    "# コーディングルールを適用する (総合評価)\n",
    "cross_1000_ps_df.loc[cross_1000_ps_df.index.get_level_values('文書ID').isin(all_df[all_df['総合'] <=2].index), '総合1-2'] = 1\n",
    "cross_1000_ps_df.loc[cross_1000_ps_df.index.get_level_values('文書ID').isin(all_df[all_df['総合'] >=4].index), '総合4-5'] = 1\n",
    "cross_1000_ps_df = cross_1000_ps_df[['ポジ','ネガ','総合1-2','総合4-5']]\n",
    "\n",
    "# DataFrame を表示する\n",
    "print(cross_1000_ps_df.shape)\n",
    "display(cross_1000_ps_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0851666",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "a0851666",
    "outputId": "20a027da-519f-4fca-e465-76598f76d1d0"
   },
   "outputs": [],
   "source": [
    "# 「カテゴリー」のクロス集計と「エリア」のクロス集計を連結する\n",
    "aggregate_ps_df = pd.concat(\n",
    "    [\n",
    "        cross_1000_ps_df.groupby(level='カテゴリー').sum(),\n",
    "        cross_1000_ps_df.groupby(level='エリア').sum()\n",
    "    ]\n",
    ")\n",
    "\n",
    "# DataFrame を表示する\n",
    "print(aggregate_ps_df.shape)\n",
    "display(aggregate_ps_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6926eb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 694
    },
    "id": "5e6926eb",
    "outputId": "3107c4fd-eb13-4668-a43f-3cf4e5bd2d07"
   },
   "outputs": [],
   "source": [
    "# 必要ライブラリのインポート\n",
    "import mca\n",
    "\n",
    "# ライブラリ mca による対応分析\n",
    "ncols = aggregate_ps_df.shape[1]\n",
    "mca_ben = mca.MCA(aggregate_ps_df, ncols=ncols, benzecri=False)\n",
    "\n",
    "# 行方向および列方向の値を取り出す\n",
    "row_coord = mca_ben.fs_r(N=2)\n",
    "col_coord = mca_ben.fs_c(N=2)\n",
    "\n",
    "# 固有値を求める\n",
    "eigenvalues = mca_ben.L\n",
    "total = np.sum(eigenvalues)\n",
    "# 寄与率を求める\n",
    "explained_inertia = 100 * eigenvalues / total\n",
    "\n",
    "# 行方向および列方向のラベルを取得する\n",
    "row_labels = aggregate_ps_df.index\n",
    "col_labels = aggregate_ps_df.columns\n",
    "\n",
    "# プロットする\n",
    "gssm_utils.plot_coresp(row_coord, col_coord, row_labels, col_labels, explained_inertia)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6914307a",
   "metadata": {
    "id": "6914307a"
   },
   "source": [
    "#### 1.3.2 ポジティブ意見の共起ネットワーク図を作成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f38f1d2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "3f38f1d2",
    "outputId": "c974f47b-9961-4b5e-cdf4-2b980d27089b"
   },
   "outputs": [],
   "source": [
    "# 必要ライブラリのインポート\n",
    "from scipy.sparse import csc_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# コーディングルール\n",
    "coding_or = coding_pos\n",
    "\n",
    "# サブルーチン\n",
    "def sort_and_plot(name, group):\n",
    "\n",
    "    # 「カテゴリー」ごとに Jaccard 係数でソートする\n",
    "    sorted_columns = np.argsort(jaccard_attrs_df.loc[name].values)[::-1][:75]\n",
    "\n",
    "    # Jaccard 係数Top 75語をソートして抽出する\n",
    "    group_cross_df = group.iloc[:,sorted_columns]\n",
    "\n",
    "    # 共起行列を作成する\n",
    "    X = group_cross_df.values\n",
    "    X = csc_matrix(X)\n",
    "    Xc = (X.T * X)\n",
    "    Xc = np.triu(Xc.toarray())\n",
    "\n",
    "    # コーディングルールで絞り込む\n",
    "    index = docs_df['表層'].str.contains(\"|\".join(coding_or))\n",
    "    group_cross_df = group_cross_df[group_cross_df.index.get_level_values('文書ID').isin(docs_df.loc[index, '文書ID'])]\n",
    "\n",
    "    # 共起行列を DataFrame に整える\n",
    "    group_cooccur_df = pd.DataFrame(Xc, columns=group_cross_df.columns, index=group_cross_df.columns)\n",
    "\n",
    "    # 共起行列の中身を Jaccard 係数に入れ替える\n",
    "    group_jaccard_df = gssm_utils.jaccard_coef(group_cooccur_df, group_cross_df)\n",
    "\n",
    "    # 抽出語の出現回数を取得する\n",
    "    word_counts = group_cross_df.sum(axis=0).values\n",
    "\n",
    "    # プロットする\n",
    "    ax = fig.add_subplot(4, 3, i+1)\n",
    "    pyvis_plot = gssm_utils.plot_cooccur_network_with_code_ax(ax, group_jaccard_df, word_counts, np.sort(group_jaccard_df.values.reshape(-1))[::-1][120], coding_or, pyvis=True, name=f\"pos-{name}.html\")\n",
    "    ax.set_title(name)\n",
    "    display(pyvis_plot)\n",
    "\n",
    "# プロットの準備\n",
    "# fig = plt.figure(figsize=(20, 28))\n",
    "fig = plt.figure(figsize=(28, 28))\n",
    "\n",
    "i = 0\n",
    "# カテゴリごとのループ\n",
    "for name, group in cross_1000_df.groupby(level='カテゴリー'):\n",
    "    # サブルーチンを呼ぶ\n",
    "    sort_and_plot(name, group)\n",
    "    i += 1\n",
    "\n",
    "    # エリアごとのループ\n",
    "    for sub_name, sub_group in group.groupby(level='エリア'):\n",
    "        # サブルーチンを呼ぶ\n",
    "        sort_and_plot(sub_name, sub_group)\n",
    "        i += 1\n",
    "\n",
    "# プロットの仕上げ\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d413fa",
   "metadata": {
    "id": "76d413fa"
   },
   "source": [
    "#### 1.3.3 ポジティブ意見の係り受けネットワーク図を作成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfb77b5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2bfb77b5",
    "outputId": "aeb419eb-de89-40ce-e068-09f96f8419e3"
   },
   "outputs": [],
   "source": [
    "# 必要ライブラリのインポート\n",
    "from scipy.sparse import csc_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# コーディングルール\n",
    "coding_or = coding_pos\n",
    "\n",
    "# サブルーチン\n",
    "def sort_and_plot(name, group, pos):\n",
    "\n",
    "    # 「カテゴリー」ごとに Jaccard 係数でソートする\n",
    "    sorted_columns = np.argsort(jaccard_attrs_df.loc[name].values)[::-1][:75]\n",
    "\n",
    "    # Jaccard 係数Top 75語をソートして抽出する\n",
    "    group_cross_df = group.iloc[:,sorted_columns]\n",
    "\n",
    "    # 抽出語の出現回数を取得する\n",
    "    word_counts = group_cross_df.sum(axis=0).values\n",
    "\n",
    "    # 共起行列を作成する\n",
    "    X = group_cross_df.values\n",
    "    X = csc_matrix(X)\n",
    "    Xc = (X.T * X)\n",
    "    Xc = np.triu(Xc.toarray())\n",
    "\n",
    "    # コーディングルールで絞り込む\n",
    "    index = docs_df['表層'].str.contains(\"|\".join(coding_or))\n",
    "    group_cross_df = group_cross_df[group_cross_df.index.get_level_values('文書ID').isin(docs_df.loc[index, '文書ID'])]\n",
    "\n",
    "    # 共起行列を DataFrame に整える\n",
    "    group_cooccur_df = pd.DataFrame(Xc, columns=group_cross_df.columns, index=group_cross_df.columns)\n",
    "\n",
    "    # 係り受け行列(条件付き確率)を初期化する (共起行列と同じ形)\n",
    "    Xd = np.zeros(group_cooccur_df.shape)\n",
    "\n",
    "    # 係り受けペアを係り受け行列(条件付き確率)に変換する\n",
    "    for (f,t), v in pair_counts.items():\n",
    "\n",
    "        # 係り元と係り先の両方が列に含まれる\n",
    "        columns = list(group_cooccur_df.columns)\n",
    "        if f in columns and t in columns:\n",
    "            i = columns.index(f)\n",
    "            j = columns.index(t)\n",
    "\n",
    "            # 条件付き確率(係り受け頻度/係り先出現回数)を求める\n",
    "            Xd[i,j] = v / word_counts[i]\n",
    "\n",
    "    # 係り受け行列(条件付き確率)を DataFrame 型に整える\n",
    "    group_dependency_df = pd.DataFrame(Xd, columns=group_cross_df.columns, index=group_cross_df.columns)\n",
    "\n",
    "    # プロットする\n",
    "    ax = fig.add_subplot(4, 3, pos+1)\n",
    "    pyvis_plot = gssm_utils.plot_cooccur_network_with_code_ax(ax, group_dependency_df, word_counts, np.sort(group_dependency_df.values.reshape(-1))[::-1][120], coding_or, pyvis=False, name=f\"pos-{name}.html\")\n",
    "    ax.set_title(name)\n",
    "    # display(pyvis_plot)\n",
    "\n",
    "    # 係り受けペアを条件付き確率で降順にソートし10件表示する\n",
    "    Xc = group_dependency_df.values\n",
    "    words = group_dependency_df.columns\n",
    "    flat_indices = np.argsort(Xc.ravel())[::-1][:20]\n",
    "    row_indices, col_indices = np.unravel_index(flat_indices, Xc.shape)\n",
    "    for idx in range(len(flat_indices)):\n",
    "        if words[row_indices[idx]] in coding_or or words[col_indices[idx]] in coding_or:\n",
    "            value = Xc[row_indices[idx], col_indices[idx]]\n",
    "            print(f\"[{name}] {words[col_indices[idx]]} - {words[row_indices[idx]]}: {value:.04f}\")\n",
    "\n",
    "# プロットの準備\n",
    "# fig = plt.figure(figsize=(20, 28))\n",
    "fig = plt.figure(figsize=(28, 28))\n",
    "\n",
    "i = 0\n",
    "# カテゴリごとのループ\n",
    "for name, group in cross_1000_df.groupby(level='カテゴリー'):\n",
    "    # サブルーチンを呼ぶ\n",
    "    sort_and_plot(name, group, i)\n",
    "    i += 1\n",
    "\n",
    "    # エリアごとのループ\n",
    "    for sub_name, sub_group in group.groupby(level='エリア'):\n",
    "        # サブルーチンを呼ぶ\n",
    "        sort_and_plot(sub_name, sub_group, i)\n",
    "        i += 1\n",
    "\n",
    "# プロットの仕上げ\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf62cfa",
   "metadata": {
    "id": "edf62cfa"
   },
   "source": [
    "#### 1.3.4 ネガティブ意見の共起ネットワーク図を作成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5184d6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1e5184d6",
    "outputId": "497c8618-2428-46eb-90f3-de7fc72debd2"
   },
   "outputs": [],
   "source": [
    "# 必要ライブラリのインポート\n",
    "from scipy.sparse import csc_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# コーディングルール\n",
    "coding_or = coding_neg\n",
    "\n",
    "# サブルーチン\n",
    "def sort_and_plot(name, group):\n",
    "\n",
    "    # 「カテゴリー」ごとに Jaccard 係数でソートする\n",
    "    sorted_columns = np.argsort(jaccard_attrs_df.loc[name].values)[::-1][:75]\n",
    "\n",
    "    # Jaccard 係数Top 75語をソートして抽出する\n",
    "    group_cross_df = group.iloc[:,sorted_columns]\n",
    "\n",
    "    # 共起行列を作成する\n",
    "    X = group_cross_df.values\n",
    "    X = csc_matrix(X)\n",
    "    Xc = (X.T * X)\n",
    "    Xc = np.triu(Xc.toarray())\n",
    "\n",
    "    # コーディングルールで絞り込む\n",
    "    index = docs_df['表層'].str.contains(\"|\".join(coding_or))\n",
    "    group_cross_df = group_cross_df[group_cross_df.index.get_level_values('文書ID').isin(docs_df.loc[index, '文書ID'])]\n",
    "\n",
    "    # 共起行列を DataFrame に整える\n",
    "    group_cooccur_df = pd.DataFrame(Xc, columns=group_cross_df.columns, index=group_cross_df.columns)\n",
    "\n",
    "    # 共起行列の中身を Jaccard 係数に入れ替える\n",
    "    group_jaccard_df = gssm_utils.jaccard_coef(group_cooccur_df, group_cross_df)\n",
    "\n",
    "    # 抽出語の出現回数を取得する\n",
    "    word_counts = group_cross_df.sum(axis=0).values\n",
    "\n",
    "    # プロットする\n",
    "    ax = fig.add_subplot(4, 3, i+1)\n",
    "    pyvis_plot = gssm_utils.plot_cooccur_network_with_code_ax(ax, group_jaccard_df, word_counts, np.sort(group_jaccard_df.values.reshape(-1))[::-1][120], coding_or, pyvis=True, name=f\"neg-{name}.html\")\n",
    "    ax.set_title(name)\n",
    "    display(pyvis_plot)\n",
    "\n",
    "# プロットの準備\n",
    "# fig = plt.figure(figsize=(20, 28))\n",
    "fig = plt.figure(figsize=(28, 28))\n",
    "\n",
    "i = 0\n",
    "# カテゴリごとのループ\n",
    "for name, group in cross_1000_df.groupby(level='カテゴリー'):\n",
    "    # サブルーチンを呼ぶ\n",
    "    sort_and_plot(name, group)\n",
    "    i += 1\n",
    "\n",
    "    # エリアごとのループ\n",
    "    for sub_name, sub_group in group.groupby(level='エリア'):\n",
    "        # サブルーチンを呼ぶ\n",
    "        sort_and_plot(sub_name, sub_group)\n",
    "        i += 1\n",
    "\n",
    "# プロットの仕上げ\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e98283",
   "metadata": {
    "id": "a5e98283"
   },
   "source": [
    "#### 1.3.5 ネガティブ意見の係り受けネットワーク図を作成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b9a68e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "33b9a68e",
    "outputId": "b5da03c7-21b6-4819-81b7-bb95dace5eb0"
   },
   "outputs": [],
   "source": [
    "# 必要ライブラリのインポート\n",
    "from scipy.sparse import csc_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# コーディングルール\n",
    "coding_or = coding_neg\n",
    "\n",
    "# サブルーチン\n",
    "def sort_and_plot(name, group, pos):\n",
    "\n",
    "    # 「カテゴリー」ごとに Jaccard 係数でソートする\n",
    "    sorted_columns = np.argsort(jaccard_attrs_df.loc[name].values)[::-1][:75]\n",
    "\n",
    "    # Jaccard 係数Top 75語をソートして抽出する\n",
    "    group_cross_df = group.iloc[:,sorted_columns]\n",
    "\n",
    "    # 抽出語の出現回数を取得する\n",
    "    word_counts = group_cross_df.sum(axis=0).values\n",
    "\n",
    "    # 共起行列を作成する\n",
    "    X = group_cross_df.values\n",
    "    X = csc_matrix(X)\n",
    "    Xc = (X.T * X)\n",
    "    Xc = np.triu(Xc.toarray())\n",
    "\n",
    "    # コーディングルールで絞り込む\n",
    "    index = docs_df['表層'].str.contains(\"|\".join(coding_or))\n",
    "    group_cross_df = group_cross_df[group_cross_df.index.get_level_values('文書ID').isin(docs_df.loc[index, '文書ID'])]\n",
    "\n",
    "    # 共起行列を DataFrame に整える\n",
    "    group_cooccur_df = pd.DataFrame(Xc, columns=group_cross_df.columns, index=group_cross_df.columns)\n",
    "\n",
    "    # 係り受け行列(条件付き確率)を初期化する (共起行列と同じ形)\n",
    "    Xd = np.zeros(group_cooccur_df.shape)\n",
    "\n",
    "    # 係り受けペアを係り受け行列(条件付き確率)に変換する\n",
    "    for (f,t), v in pair_counts.items():\n",
    "\n",
    "        # 係り元と係り先の両方が列に含まれる\n",
    "        columns = list(group_cooccur_df.columns)\n",
    "        if f in columns and t in columns:\n",
    "            i = columns.index(f)\n",
    "            j = columns.index(t)\n",
    "\n",
    "            # 条件付き確率(係り受け頻度/係り先出現回数)を求める\n",
    "            Xd[i,j] = v / word_counts[i]\n",
    "\n",
    "    # 係り受け行列(条件付き確率)を DataFrame 型に整える\n",
    "    group_dependency_df = pd.DataFrame(Xd, columns=group_cross_df.columns, index=group_cross_df.columns)\n",
    "\n",
    "    # プロットする\n",
    "    ax = fig.add_subplot(4, 3, pos+1)\n",
    "    pyvis_plot = gssm_utils.plot_cooccur_network_with_code_ax(ax, group_dependency_df, word_counts, np.sort(group_dependency_df.values.reshape(-1))[::-1][120], coding_or, pyvis=False, name=f\"pos-{name}.html\")\n",
    "    ax.set_title(name)\n",
    "    # display(pyvis_plot)\n",
    "\n",
    "    # 係り受けペアを条件付き確率で降順にソートし10件表示する\n",
    "    Xc = group_dependency_df.values\n",
    "    words = group_dependency_df.columns\n",
    "    flat_indices = np.argsort(Xc.ravel())[::-1][:10]\n",
    "    row_indices, col_indices = np.unravel_index(flat_indices, Xc.shape)\n",
    "    for idx in range(len(flat_indices)):\n",
    "        if words[row_indices[idx]] in coding_or or words[col_indices[idx]] in coding_or:\n",
    "            value = Xc[row_indices[idx], col_indices[idx]]\n",
    "            print(f\"[{name}] {words[col_indices[idx]]} - {words[row_indices[idx]]}: {value:.04f}\")\n",
    "\n",
    "# プロットの準備\n",
    "# fig = plt.figure(figsize=(20, 28))\n",
    "fig = plt.figure(figsize=(28, 28))\n",
    "\n",
    "i = 0\n",
    "# カテゴリごとのループ\n",
    "for name, group in cross_1000_df.groupby(level='カテゴリー'):\n",
    "    # サブルーチンを呼ぶ\n",
    "    sort_and_plot(name, group, i)\n",
    "    i += 1\n",
    "\n",
    "    # エリアごとのループ\n",
    "    for sub_name, sub_group in group.groupby(level='エリア'):\n",
    "        # サブルーチンを呼ぶ\n",
    "        sort_and_plot(sub_name, sub_group, i)\n",
    "        i += 1\n",
    "\n",
    "# プロットの仕上げ\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e8b67f",
   "metadata": {
    "id": "15e8b67f"
   },
   "source": [
    "#### 1.3.4 本文の参照 (エリアで絞る)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01558796",
   "metadata": {
    "id": "01558796"
   },
   "source": [
    "「登別」と「道後」で「すばらしい」という単語が含まれている口コミを表示する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08190c40",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 537
    },
    "id": "08190c40",
    "outputId": "59990a70-45a0-41b3-a578-2d745d4c0300"
   },
   "outputs": [],
   "source": [
    "# 検索条件\n",
    "search_index = \\\n",
    "    all_df['エリア'].isin(['01_登別', '04_道後']) & \\\n",
    "    (all_df['コメント'].str.contains('素晴らしい') | all_df['コメント'].str.contains('すばらしい'))\n",
    "\n",
    "# 検索する\n",
    "result_df = all_df[search_index]\n",
    "\n",
    "# DataFrame を表示する\n",
    "print(result_df.shape)\n",
    "display(result_df.head())\n",
    "\n",
    "# CSV に保存する\n",
    "result_df.to_csv(\"output-1.csv\", header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bcbfdb",
   "metadata": {
    "id": "f5bcbfdb"
   },
   "source": [
    "「東京」と「福岡」で「うるさい」という単語が含まれている口コミを表示する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8a5acf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "id": "ef8a5acf",
    "outputId": "c9f284b0-f2a0-4f90-a111-1f41e439b1ce",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 検索条件\n",
    "search_index = \\\n",
    "    all_df['エリア'].isin(['08_東京', '10_福岡']) & \\\n",
    "    all_df['コメント'].str.contains('うるさい')\n",
    "\n",
    "# 検索する\n",
    "result_df = all_df[search_index]\n",
    "\n",
    "# DataFrame を表示する\n",
    "print(result_df.shape)\n",
    "display(result_df.head())\n",
    "\n",
    "# CSV に保存する\n",
    "result_df.to_csv(\"output-2.csv\", header=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "01-colab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
